{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snowdenstyll/keno/blob/main/jupyterNotebooks/Keno_Lottery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cqI3K4Z1_9y_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hcU8I8YcA5-E"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"2024.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjWDe-HI_9zD",
        "outputId": "7ec97669-791f-4c0f-f576-b8026b8cde74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 128 entries, 0 to 127\n",
            "Data columns (total 22 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   PlayDate  128 non-null    object\n",
            " 1   AP        128 non-null    object\n",
            " 2   N01       128 non-null    int64 \n",
            " 3   N02       128 non-null    int64 \n",
            " 4   N03       128 non-null    int64 \n",
            " 5   N04       128 non-null    int64 \n",
            " 6   N05       128 non-null    int64 \n",
            " 7   N06       128 non-null    int64 \n",
            " 8   N07       128 non-null    int64 \n",
            " 9   N08       128 non-null    int64 \n",
            " 10  N09       128 non-null    int64 \n",
            " 11  N10       128 non-null    int64 \n",
            " 12  N11       128 non-null    int64 \n",
            " 13  N12       128 non-null    int64 \n",
            " 14  N13       128 non-null    int64 \n",
            " 15  N14       128 non-null    int64 \n",
            " 16  N15       128 non-null    int64 \n",
            " 17  N16       128 non-null    int64 \n",
            " 18  N17       128 non-null    int64 \n",
            " 19  N18       128 non-null    int64 \n",
            " 20  N19       128 non-null    int64 \n",
            " 21  N20       128 non-null    int64 \n",
            "dtypes: int64(20), object(2)\n",
            "memory usage: 22.1+ KB\n"
          ]
        }
      ],
      "source": [
        "df.head()\n",
        "df.tail()\n",
        "df.info()\n",
        "df.describe()\n",
        "df.drop(['PlayDate', 'AP'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IFxUoUUa_9zG"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler().fit(df.values)\n",
        "transformed_dataset = scaler.transform(df.values)\n",
        "transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VO8P7MGA_9zI"
      },
      "outputs": [],
      "source": [
        "# All our games\n",
        "number_of_rows = df.values.shape[0]\n",
        "# Amount of games we need to take into consideration for prediction\n",
        "window_length = 10\n",
        "number_of_features = df.values.shape[1]\n",
        "\n",
        "X = np.empty([ number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "y = np.empty([ number_of_rows - window_length, number_of_features], dtype=float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W8Od3t8__9zK"
      },
      "outputs": [],
      "source": [
        "for i in range(0, number_of_rows-window_length):\n",
        "    X[i] = transformed_df.iloc[i : i+window_length, 0 : number_of_features]\n",
        "    y[i] = transformed_df.iloc[i+window_length : i+window_length+1, 0 : number_of_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b9d815xa_9zN"
      },
      "outputs": [],
      "source": [
        "# Recurrent Neural Netowrk (RNN) with Long Short Term Memory (LSTM)\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "batch_size = 70\n",
        "\n",
        "# Initialising the RNN\n",
        "model = Sequential()\n",
        "# Adding the input layer and the LSTM layer\n",
        "model.add(Bidirectional(LSTM(256,\n",
        "                        input_shape = (window_length, number_of_features),\n",
        "                        return_sequences = True)))\n",
        "# Adding a first Dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a second LSTM layer\n",
        "model.add(Bidirectional(LSTM(256,\n",
        "                        input_shape = (window_length, number_of_features),\n",
        "                        return_sequences = True)))\n",
        "# Adding a second Dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a third LSTM layer\n",
        "model.add(Bidirectional(LSTM(256,\n",
        "                        input_shape = (window_length, number_of_features),\n",
        "                        return_sequences = True)))\n",
        "# Adding a fourth LSTM layer\n",
        "model.add(Bidirectional(LSTM(256,\n",
        "                        input_shape = (window_length, number_of_features),\n",
        "                        return_sequences = False)))\n",
        "# Adding a fourth Dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding the first output layer\n",
        "model.add(Dense(70))\n",
        "# Adding the last output layer\n",
        "model.add(Dense(number_of_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE0G1oQc_9zN",
        "outputId": "d516095c-da25-4dc1-aea0-7612c3cf302e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 - 34s - loss: 1.0193 - accuracy: 0.0508 - 34s/epoch - 17s/step\n",
            "Epoch 2/1000\n",
            "2/2 - 1s - loss: 1.0155 - accuracy: 0.0763 - 1s/epoch - 595ms/step\n",
            "Epoch 3/1000\n",
            "2/2 - 1s - loss: 1.0097 - accuracy: 0.0763 - 1s/epoch - 608ms/step\n",
            "Epoch 4/1000\n",
            "2/2 - 1s - loss: 1.0068 - accuracy: 0.0593 - 1s/epoch - 599ms/step\n",
            "Epoch 5/1000\n",
            "2/2 - 1s - loss: 1.0020 - accuracy: 0.0763 - 1s/epoch - 589ms/step\n",
            "Epoch 6/1000\n",
            "2/2 - 1s - loss: 0.9967 - accuracy: 0.0508 - 1s/epoch - 590ms/step\n",
            "Epoch 7/1000\n",
            "2/2 - 2s - loss: 0.9921 - accuracy: 0.1017 - 2s/epoch - 839ms/step\n",
            "Epoch 8/1000\n",
            "2/2 - 2s - loss: 0.9861 - accuracy: 0.0763 - 2s/epoch - 795ms/step\n",
            "Epoch 9/1000\n",
            "2/2 - 1s - loss: 0.9794 - accuracy: 0.0847 - 1s/epoch - 588ms/step\n",
            "Epoch 10/1000\n",
            "2/2 - 1s - loss: 0.9722 - accuracy: 0.1356 - 1s/epoch - 597ms/step\n",
            "Epoch 11/1000\n",
            "2/2 - 1s - loss: 0.9659 - accuracy: 0.0847 - 1s/epoch - 593ms/step\n",
            "Epoch 12/1000\n",
            "2/2 - 1s - loss: 0.9583 - accuracy: 0.0763 - 1s/epoch - 604ms/step\n",
            "Epoch 13/1000\n",
            "2/2 - 1s - loss: 0.9485 - accuracy: 0.0847 - 1s/epoch - 587ms/step\n",
            "Epoch 14/1000\n",
            "2/2 - 1s - loss: 0.9362 - accuracy: 0.1102 - 1s/epoch - 591ms/step\n",
            "Epoch 15/1000\n",
            "2/2 - 1s - loss: 0.9284 - accuracy: 0.1017 - 1s/epoch - 592ms/step\n",
            "Epoch 16/1000\n",
            "2/2 - 1s - loss: 0.9153 - accuracy: 0.1271 - 1s/epoch - 592ms/step\n",
            "Epoch 17/1000\n",
            "2/2 - 2s - loss: 0.9036 - accuracy: 0.1356 - 2s/epoch - 916ms/step\n",
            "Epoch 18/1000\n",
            "2/2 - 1s - loss: 0.8898 - accuracy: 0.1441 - 1s/epoch - 749ms/step\n",
            "Epoch 19/1000\n",
            "2/2 - 1s - loss: 0.8817 - accuracy: 0.1271 - 1s/epoch - 588ms/step\n",
            "Epoch 20/1000\n",
            "2/2 - 1s - loss: 0.8751 - accuracy: 0.1271 - 1s/epoch - 602ms/step\n",
            "Epoch 21/1000\n",
            "2/2 - 1s - loss: 0.8548 - accuracy: 0.1186 - 1s/epoch - 582ms/step\n",
            "Epoch 22/1000\n",
            "2/2 - 1s - loss: 0.8490 - accuracy: 0.1356 - 1s/epoch - 586ms/step\n",
            "Epoch 23/1000\n",
            "2/2 - 1s - loss: 0.8260 - accuracy: 0.1525 - 1s/epoch - 592ms/step\n",
            "Epoch 24/1000\n",
            "2/2 - 1s - loss: 0.8123 - accuracy: 0.1356 - 1s/epoch - 602ms/step\n",
            "Epoch 25/1000\n",
            "2/2 - 1s - loss: 0.8052 - accuracy: 0.1356 - 1s/epoch - 584ms/step\n",
            "Epoch 26/1000\n",
            "2/2 - 1s - loss: 0.7918 - accuracy: 0.1356 - 1s/epoch - 634ms/step\n",
            "Epoch 27/1000\n",
            "2/2 - 2s - loss: 0.7822 - accuracy: 0.1186 - 2s/epoch - 935ms/step\n",
            "Epoch 28/1000\n",
            "2/2 - 1s - loss: 0.7663 - accuracy: 0.1695 - 1s/epoch - 659ms/step\n",
            "Epoch 29/1000\n",
            "2/2 - 1s - loss: 0.7484 - accuracy: 0.1356 - 1s/epoch - 596ms/step\n",
            "Epoch 30/1000\n",
            "2/2 - 1s - loss: 0.7422 - accuracy: 0.1356 - 1s/epoch - 587ms/step\n",
            "Epoch 31/1000\n",
            "2/2 - 1s - loss: 0.7365 - accuracy: 0.1525 - 1s/epoch - 591ms/step\n",
            "Epoch 32/1000\n",
            "2/2 - 1s - loss: 0.7275 - accuracy: 0.1525 - 1s/epoch - 597ms/step\n",
            "Epoch 33/1000\n",
            "2/2 - 1s - loss: 0.7122 - accuracy: 0.1441 - 1s/epoch - 585ms/step\n",
            "Epoch 34/1000\n",
            "2/2 - 1s - loss: 0.7136 - accuracy: 0.1610 - 1s/epoch - 596ms/step\n",
            "Epoch 35/1000\n",
            "2/2 - 1s - loss: 0.6969 - accuracy: 0.1695 - 1s/epoch - 594ms/step\n",
            "Epoch 36/1000\n",
            "2/2 - 1s - loss: 0.6850 - accuracy: 0.1949 - 1s/epoch - 691ms/step\n",
            "Epoch 37/1000\n",
            "2/2 - 2s - loss: 0.6769 - accuracy: 0.1949 - 2s/epoch - 900ms/step\n",
            "Epoch 38/1000\n",
            "2/2 - 1s - loss: 0.6791 - accuracy: 0.1695 - 1s/epoch - 662ms/step\n",
            "Epoch 39/1000\n",
            "2/2 - 1s - loss: 0.6557 - accuracy: 0.1780 - 1s/epoch - 602ms/step\n",
            "Epoch 40/1000\n",
            "2/2 - 1s - loss: 0.6473 - accuracy: 0.1525 - 1s/epoch - 601ms/step\n",
            "Epoch 41/1000\n",
            "2/2 - 1s - loss: 0.6554 - accuracy: 0.1356 - 1s/epoch - 595ms/step\n",
            "Epoch 42/1000\n",
            "2/2 - 1s - loss: 0.6391 - accuracy: 0.1864 - 1s/epoch - 590ms/step\n",
            "Epoch 43/1000\n",
            "2/2 - 1s - loss: 0.6250 - accuracy: 0.1780 - 1s/epoch - 588ms/step\n",
            "Epoch 44/1000\n",
            "2/2 - 1s - loss: 0.6168 - accuracy: 0.1610 - 1s/epoch - 575ms/step\n",
            "Epoch 45/1000\n",
            "2/2 - 1s - loss: 0.6199 - accuracy: 0.1610 - 1s/epoch - 578ms/step\n",
            "Epoch 46/1000\n",
            "2/2 - 1s - loss: 0.6081 - accuracy: 0.1864 - 1s/epoch - 727ms/step\n",
            "Epoch 47/1000\n",
            "2/2 - 2s - loss: 0.5858 - accuracy: 0.1695 - 2s/epoch - 918ms/step\n",
            "Epoch 48/1000\n",
            "2/2 - 1s - loss: 0.6066 - accuracy: 0.1695 - 1s/epoch - 591ms/step\n",
            "Epoch 49/1000\n",
            "2/2 - 1s - loss: 0.5801 - accuracy: 0.1695 - 1s/epoch - 598ms/step\n",
            "Epoch 50/1000\n",
            "2/2 - 1s - loss: 0.5929 - accuracy: 0.1780 - 1s/epoch - 601ms/step\n",
            "Epoch 51/1000\n",
            "2/2 - 1s - loss: 0.5776 - accuracy: 0.1441 - 1s/epoch - 601ms/step\n",
            "Epoch 52/1000\n",
            "2/2 - 2s - loss: 0.5661 - accuracy: 0.1441 - 2s/epoch - 774ms/step\n",
            "Epoch 53/1000\n",
            "2/2 - 1s - loss: 0.5745 - accuracy: 0.2034 - 1s/epoch - 594ms/step\n",
            "Epoch 54/1000\n",
            "2/2 - 1s - loss: 0.5659 - accuracy: 0.1695 - 1s/epoch - 601ms/step\n",
            "Epoch 55/1000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss ='mse', metrics=['accuracy'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95, random_state=95)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, batch_size=batch_size, epochs=1000, verbose=2)\n",
        "#history = model.fit(X_train, y_train, batch_size=100, epochs=600, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUeOIrVQ8042"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=1)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlnCW2T1OxEx"
      },
      "outputs": [],
      "source": [
        "#history = model.fit(X_train, y_train, batch_size=50, epochs=100, verbose=2)\n",
        "#history = model.fit(X_train, y_train, batch_size=50, epochs=100, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt2Btz2P_9zO"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "to_predict = df1.tail(window_length)\n",
        "to_predict.drop([to_predict.index[-1]],axis=0, inplace=True)\n",
        "to_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5frjfOID1el"
      },
      "outputs": [],
      "source": [
        "prediction = np.array(df.tail(1))\n",
        "\n",
        "x_next = scaler.transform(to_predict)\n",
        "y_pred = model.predict(np.array([x_next]))\n",
        "\n",
        "temp = np.array(scaler.inverse_transform(y_pred).astype(int)[0])\n",
        "combined_array = np.concatenate((temp, np.array(prediction[0])))\n",
        "winning_numbers = np.bincount(combined_array)\n",
        "winners = np.unique(combined_array)\n",
        "\n",
        "uniques, uniq_idx, counts = np.unique(combined_array,return_index=True,return_counts=True)\n",
        "duplicates = combined_array[ uniq_idx[counts>=2] ]  # <--- Get duplicates\n",
        "\n",
        "top_5_indices = np.argsort(y_pred[0], axis=0)\n",
        "prediction = scaler.inverse_transform(y_pred).astype(int)\n",
        "\n",
        "top_5_numbers = []\n",
        "for index in top_5_indices:\n",
        "    # Access the corresponding number in the top_10_predictions array\n",
        "    number = prediction[0, index]\n",
        "    # Append the number to the top_5_numbers array\n",
        "    top_5_numbers.append(number)\n",
        "\n",
        "print(\"The top 5 indices\", top_5_indices)\n",
        "print(\"The top 5 numbers:\", top_5_numbers)\n",
        "\n",
        "print(\"The predicted numbers for the lottery game are:\", scaler.inverse_transform(y_pred).astype(int)[0])\n",
        "print(\"The actual numbers in the last lottery game were:\", prediction[0])\n",
        "print(\"\\n\")\n",
        "print(\"winners:\", duplicates)\n",
        "print(len(duplicates)/20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dNEQTJYxOUv"
      },
      "source": [
        "# Predict the next set of numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzGKPd0S66O8"
      },
      "outputs": [],
      "source": [
        "next = df1.copy()\n",
        "next = next.tail(window_length)\n",
        "next = np.array(next)\n",
        "\n",
        "x_next = scaler.transform(next)\n",
        "y_next_pred = model.predict(np.array([x_next]))\n",
        "prediction = scaler.inverse_transform(y_next_pred).astype(int)\n",
        "print(\"The predicted numbers for the lottery game:\", temp)\n",
        "print(\"\\n\")\n",
        "top_5_indices = np.argsort(y_next_pred[0], axis=0)[-5:]\n",
        "top_5_numbers = []\n",
        "for index in top_5_indices:\n",
        "    # Access the corresponding number in the top_10_predictions array\n",
        "    number = prediction[0, index]\n",
        "    # Append the number to the top_5_numbers array\n",
        "    top_5_numbers.append(number)\n",
        "\n",
        "\n",
        "print(\"The top 5 indices\", top_5_indices)\n",
        "print(\"The top 5 numbers:\", top_5_numbers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcOnZYU7JkMG"
      },
      "outputs": [],
      "source": [
        "next = df1.copy()\n",
        "next = next.tail(window_length)\n",
        "next = np.array(next)\n",
        "\n",
        "x_next = scaler.transform(next)\n",
        "y_next_pred = model.predict(np.array([x_next]))\n",
        "\n",
        "# Get the actual values of the top 10 predictions\n",
        "prediction = scaler.inverse_transform(y_next_pred).astype(int)\n",
        "\n",
        "# Get the indices of the top 10 predictions (change axis=0 if predictions are along a different axis)\n",
        "top_10_indices = np.argsort(y_pred[0], axis=0)[-10:]\n",
        "top_5_indices = np.argsort(y_pred[0], axis=0)[-5:]\n",
        "\n",
        "top_10_numbers = []\n",
        "top_5_numbers = []\n",
        "\n",
        "# index [0,2,4] usually are correct\n",
        "# Loop through each index in top_10_indices\n",
        "for index in top_10_indices:\n",
        "    # Access the corresponding number in the top_10_predictions array\n",
        "    number = prediction[0, index]\n",
        "\n",
        "    # Append the number to the top_10_numbers array\n",
        "    top_10_numbers.append(number)\n",
        "\n",
        "for index in top_5_indices:\n",
        "    # Access the corresponding number in the top_10_predictions array\n",
        "    number = prediction[0, index]\n",
        "\n",
        "    # Append the number to the top_10_numbers array\n",
        "    top_5_numbers.append(number)\n",
        "\n",
        "print(\"The top 5 indices\", top_5_indices)\n",
        "print(\"The top 5 numbers:\", top_5_numbers)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"The top 10 indices\", top_10_indices)\n",
        "print(\"The top 10 numbers:\", top_10_numbers)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"The predicted numbers:\", prediction)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}